{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gzip\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"|||\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/\"\n",
    "train_filename = \"topicclass/topicclass_train.txt\"\n",
    "valid_filename = \"topicclass/topicclass_valid.txt\"\n",
    "test_filename = \"topicclass/topicclass_test.txt\"\n",
    "word2vec_filename = \"GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "label2index = defaultdict(lambda: len(label2index))\n",
    "for fname in [train_filename, valid_filename, test_filename]:\n",
    "    with open(data_dir + fname, 'r') as f:\n",
    "        for line in f:\n",
    "            label, words = line.split(delimiter)\n",
    "            if fname != test_filename:\n",
    "                label2index[label]\n",
    "            words = words.strip().split()\n",
    "            for word in words:\n",
    "                vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bin_vec(vocab, fname=\"\"):\n",
    "    known_word_vecs = {}\n",
    "    known_word_indices = defaultdict(lambda: len(known_word_indices))\n",
    "    with gzip.open(fname, 'rb') as w2vfile:\n",
    "        header = w2vfile.readline()\n",
    "        vocab_sz, embed_sz = map(int, header.split())\n",
    "        embed_readlen = np.dtype('float32').itemsize * embed_sz\n",
    "        for v in tqdm(range(vocab_sz)):\n",
    "            word = []\n",
    "                while True:\n",
    "                c = w2vfile.read(1)\n",
    "                if c == b' ':\n",
    "                    break\n",
    "                if c != b'\\n':\n",
    "                    word.append(c)\n",
    "            word = b''.join(word).decode('utf-8')\n",
    "            embedding = w2vfile.read(embed_readlen)\n",
    "            if word in vocab:\n",
    "                known_word_indices[word]\n",
    "                w2i[word]\n",
    "                known_word_vecs[word] = np.frombuffer(embedding, dtype='float32')\n",
    "    return known_word_indices, known_word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d060e0077b4a40acfffa2c7a97e12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w2i = defaultdict(lambda: len(w2i))\n",
    "known_word_indices, known_word_vecs = load_bin_vec(vocab, data_dir + word2vec_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104896 138378 0.7580395727644568\n"
     ]
    }
   ],
   "source": [
    "print(len(known_word_indices), len(vocab), len(known_word_indices) / len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_word_indices = defaultdict(lambda: len(unknown_word_indices))\n",
    "for word in vocab:\n",
    "    if word not in known_word_indices:\n",
    "        unknown_word_indices[word]\n",
    "        w2i[word]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
